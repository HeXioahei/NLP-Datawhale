# 赛题初体验

十分详细的小白教程，30分钟速通，带我们零基础体验提交作品的全过程！[从零入门NLP竞赛 - 飞书云文档 (feishu.cn)](https://datawhaler.feishu.cn/wiki/TObSwHZdFi2y0XktauWcolpcnyf)



# 四类NLP任务

* **序列标注**：比如中文分词，词性标注，命名实体识别，语义角色标注等，其共同点是句子中每一个单词都要求模型根据上下文给出一个分类类别。

* **分类任务**：比如我们常见的文本分类、情感计算等，其特点是无论文章多长，总体给出一个分类即可。

* **句子关系判断**：比如问答推理、语义改写、自然语言推理等，特点是给定两个句子，模型判断出两个句子是否具备某种语义关系。

* **生成式任务**：比如机器翻译、文本摘要、写诗造句、看图说话等，特点是输入文本内容后，需要自主生成另外一段文字。
  
  

# 机器翻译

将一种语言的文本自动转换为另一种语言的文本

演变过程：基于规则的方法 -＞统计方法 -＞深度学习方法

### 基于规则的机器翻译（1950s-1980s）

1. **原理**：利用语言学家编写的**语法规则**和**词典**进行翻译

2. **缺点**：**灵活性**和**适应性**较差，**计算**低效，最严重的缺陷在于其缺乏翻译过程中对上下文信息的**建模**，**鲁棒性**（系统或算法对于随机噪声、异常情况和攻击等意外干扰的抗干扰能力）不佳

3. **优点**：理论清晰

### 基于统计的机器翻译（1990s-2000s）

1. **原理**：**数据**驱动，通过**分析**大量双语文本，自动学习源语言和目标语言之间的**对应关系**，从而实现翻译

2. **优点**：处理**多义词**和**语言变异的**效果好

3. **缺点**：依赖大量数据

4. **主流方法**：基于**词**的统计机器翻译（Word-based MT），基于**短语**的统计机器翻译（Phrase-based SMT）

5. **步骤**：预处理、句子对齐、词对齐、短语抽取、短语特征准备、语言模型训练

### 基于神经网络的机器翻译（2010s-present）（Neural Machine Translation，简称NMT）

1. **原理**：使用**深度神经网络模型**（如长短期记忆网络（LSTM）和 Transformer），自动学习源语言和目标语言之间的复杂映射关系，无需人工设计特征或规则。

2. **优点**：在翻译**质量**、**速度**和**适应性**方面取得了显著进步
   
   

# 数据划分

数据集被划分为三个部分：

1. 训练集（Training Set）

2. 开发集（Development Set，也常被称为验证集，Validation Set）

3. 测试集（Test Set）

### 训练集

* **作用**：**训练模型**，使模型学习input与output之间的映射关系。模型会根据训练集中的样本调整其参数，以最小化预测误差。

* **目标**：让模型在训练数据上尽可能地**拟合**好。

### 开发集/验证集

* **作用**：在模型训练过程中**调整超参数**、**选择模型架构**以及**防止过拟合**，**评估**模型在未见过的数据上的表现
* **目标**：选择最佳的模型配置，避免过度拟合，确保泛化能力

### 测试集

* **作用**：最终评估模型的性能，衡量模型实际应用效果。最接近真实世界数据。

* **目标**：提供一个公正、无偏见的性能估计。
  
  

# 评估指标BLEU-4

BLEU，全称为 **Bilingual Evaluation Understudy**（双语评估替换），是一种**对生成语句**进行评估的指标，用于衡量**计算机生成的翻译与一组参考译文之间的相似度**。这个指标特别关注 **n-grams**（连续的n个词）的精确匹配，可以被认为是对翻译准确性和流利度的一种**统计估计**。最终的BLEU分数是一个介于0到1之间的数值。

**BLEU-4** 特指在计算时考虑四元组（即连续四个词）的匹配情况。

**BLEU** 评估指标的特点：

* 优点：计算速度快、计算成本低、容易理解、与具体语言无关、和人类给的评估高度相关。

* 缺点：不考虑语言表达（语法）上的准确性；测评精度会受常用词的干扰；短译句的测评精度有时会较高；没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定。



# 四、baseline 提升与思考

1. 由于对两个参数`N`和`N_EPOCHS`进行了扩大，使得训练的数据更多，所以翻译的效果提升了两倍。

2. 这两个参数的调整是存在“界”的，超过这个“界”，效果反而会下降。根据先前学过的机器学习的些许相关知识，我的思考与想法是，模型的损失函数存在一个最小值，我们通过不断调整，来获得合适参数，来使得损失函数最小，所以，这两个参数调得越大不一定越好，要合适才好。当然，太小的话，也远远达不到好效果。


