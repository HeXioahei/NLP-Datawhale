

> *本文的**知识点**主要来自：[‬‍​​‌﻿​‌​​‌﻿​‬​‌﻿​﻿﻿﻿​​​﻿​​‬​﻿​​﻿​​​‌‌​‌Task2：从baseline代码详解入门深度学习 - 飞书云文档 (feishu.cn)](https://datawhaler.feishu.cn/wiki/PztLwkofsi95oak2Iercw9hkn2g)*

上一篇文章：[Task1 #NLP学习笔记#Datawhale AI训练营#讯飞AI开发者大赛-CSDN博客](https://blog.csdn.net/hxh_230810/article/details/140424257?spm=1001.2014.3001.5501)



# 代码文件

task2原版代码：[Task2-baseline](D:\Code\ipynbcode\Task2-baseline.ipynb)                               N=100, N_EPOCHS=5, 运行用时约18分钟, 得分0.0049

<mark>task2原版代码+详细注解</mark>：[Task2-baseline-detailed]("D:\Code\ipynbcode\Task2-baseline-detailed.ipynb")

task2微调版：只改了N和N_EPOCHS。                    N=10000, N_EPOCHS=15, 运行用时约63分钟，bleu=21.34, 得分0.1826



*怎么调参跑的都很慢，分数也不高。所以，急速开始学习Task3——transformer吧*

 [Task3：基于Transformer解决机器翻译任务 - 飞书云文档 (feishu.cn)](https://datawhaler.feishu.cn/wiki/OgQWwkYkviPfpwkE1ZmcXwcWnAh)



另外附上一份<mark>task1的代码详解</mark>：[Task1-baseline代码详解]("D:\MyFiles\TypedownNotes\task1代码分析.md") 运行较快，且得分可以达到0.53



# 配置环境

> *具体教程：[‬‍​​‌﻿​‌​​‌﻿​‬​‌﻿​﻿﻿﻿​​​﻿​​‬​﻿​​﻿​​​‌‌​‌Task2：从baseline代码详解入门深度学习 - 飞书云文档 (feishu.cn)](https://datawhaler.feishu.cn/wiki/PztLwkofsi95oak2Iercw9hkn2g)*

### 一些需要额外引入的包：

* **torchtext**：是一个用于**NLP**的库，提供了**数据预处理**、**词汇构建**、**序列化**和**批处理**等功能，特别适合**文本分类**、**情感分析**、**机器翻译**等任务。

* **jieba**：是一个**中文分词库**，用于将中文文本切成有意义的词语。

* **sacrebleu**：用于**评估**机器翻译质量的工具，主要通过计算**BLEU**得分来衡量生成文本与参考译文之间的相似度。

* **spacy**：是一个强大的自然语言处理库，支持70+语言的分词和训练。

*（分词：将长文本分解为以字词为单位的数据结构，方便分析处理）*

需要安装`spacy`用于英文的`tokenizer`

*sm：效率快*

*trf：精确度高*

### 一些注意事项

1. 注意文件的路径

2. 注意选择的包名
   
   

# 数据预处理

这是确保模型能够有效学习**源语言到目标语言映射**的关键步骤。旨在**清理**、**标准化**和**转换**数据，使之适合模型训练。

以下是常见的几个处理步骤：

* **清洗和规范化数据**
  
  * **去除无关信息**：删除HTML标签、特殊字符、非文本内容等，确保文本的**纯净性**（去除“脏”数据，如“Joey. （掌声） （掌声） 乔伊”这种括号里的声音词）
  
  * **统一格式**：转换所有文本为**小写**，确保**一致**性；**标准化**日期、数字等格式。
  
  * **分句和分段**：将长文本分割成句子或段落，便于处理和训练。

* **分词**
  
  * **分词**：将句子分解成**单词**或**词素**（构成单词的基本组成部分，一个词素可以是一个完整的单词，也可以是单词的一部分，但每一个词素都至少携带一部分语义或语法信息）。我们这里使用了使用`jieba` 对中文进行分词，使用`spaCy`对英文进行分词。

* **构建词汇表和词向量**
  
  * **词汇表构建**：从训练数据中收集所有**出现过**的词汇，构建词汇表，并为每个词分配一个唯一的**索引**。
  
  * **词向量**：使用预训练的词向量或自己训练词向量，将词汇表中的词映射到高维空间中的向量，以捕捉语义信息（当前大模型领域训练的 embedding 模型就是用来完成此任务的）。

* **序列截断和填充**
  
  * **序列截断**：限制输入序列的长度（过长的序列可能增加**计算成本**，同时也可能包含**冗余信息**）
  
  * **序列填充**：将所有序列填充至**相同的长度**，便于批量处理。通常使用`<PAD>`标记填充。

* **添加特殊标记**
  
  * **序列开始和结束标记**：在序列两端添加`<SOS>`（Sequence Start）和`<EOS>`（Sequence End）标记，帮助模型识别序列的**起始**和**结束**。
  
  * **未知词标记**：为不在词汇表中的词添加`<UNK>`（Unknown）标记，使模型能够处理未见过的词汇。

* **数据增强**
  
  * **随机替换或删除词**：在训练数据中随机替换或删除一些词，增强模型的**鲁棒性**（系统或算法对于随机噪声、异常情况和攻击等意外干扰的抗干扰能力）。
  
  * **同义词替换**：使用同义词替换原文中的词，增加训练数据的多样性。

* **数据分割**
  
  * **划分数据集**：将数据划分为**训练集**、**验证集**和**测试集**，分别用于**模型训练**、**参数调整**和最终**性能评估**（该赛题中已划分好，不需要自己进行划分）
    
    
    
    

# 模型训练

说到**神经机器翻译**就不得不提**编码器-解码器模型**，或**编码器-解码器框架（EncoderDecoder Paradigm）**。其用于描述**输入­输出之间关系**。

*例如，在电视系统上为了便于视频的传播，会使用各种编码器将视频编码成数字信号，在客户端，相应的解码器组件会把收到的数字信号解码为视频。*

机器翻译问题完美贴合这种编码器-­解码器结构的特点。可以将源语言编码为类似信息传输中的数字信号，然后利用解码器对其进行转换，生成目标语言。

下面是一个应用编码器­解码器结构来解决汉译英的例子：

<img src="file:///D:/photos/016740b0-501a-4115-b6ec-c24722065869.png" title="" alt="" style="zoom:67%;">

给定一个中文句子“我/对/你/感到/满意”，**编码器**会将这句话编码成一个**实数向量(0.2, −1, 6, 5, 0.7, −2)**，这个向量就是源语言句子的“表示”结果。**神经机器翻译模型**把这个向量等同于**输入序列**。向量中的数字并没有实际的意义，然而**解码器**却能从中提取到源语言句子中所包含的信息。*也有研究人员把向量的每一个维度看作是一个“特征”，这样源语言句子就被表示成多个“特征”的联合，而且这些特征可以被自动学习*。有了这样的源语言句子的“表示”，**解码器**可以把这个实数向量作为输入，然后逐词生成目标语言句子“I am satisfied with you”。



在源语言句子的表示形式确定之后，需要设计相应的编码器和解码器结构。在当今主流的神经机器翻译系统中，编码器由**词嵌入层**和**中间网络层**组成：

* 当输入一串单词序列时，**词嵌入层**(embedding)会将每个单词映射到多维实数表示空间，这个过程也被称为**词嵌入**。

* 之后**中间层**会对词嵌入向量进行更深层的抽象，得到输入单词序列的中间表示。**中间层的实现方式**有很多，比如：**循环神经网络、卷积神经网络、自注意力机制**等都是模型常用的结构。

**解码器的结构基本上和编码器是一致的**。

* 在基于**循环神经网络**的翻译模型中，解码器只比编码器多了**输出层**，用于输出每个目标语言位置的单词生成概率；

* 而在基于**自注意力机制**的翻译模型中，除了**输出层**，解码器还比编码器多一个**编码­解码注意力子层**，用于帮助模型更好地利用源语言信息。
  
  

以基于**循环神经网络**的机器翻译模型为例，说明其整体结构。

左侧为**编码器部分**，源语言单词按照其在文本序列中的先后顺序被依次送入到循环神经网络（RNN）当中。在每个**时间步** $t$ 中，模型依据送入的**源语言单词** $x_{t} $ 来修改并维护其模型内部对应的**隐状态** $h_{t}$，这个隐状态编码了输入的源语言序列前 $ t $ 个时刻的所有必要信息。按照这种方式当 m 个输入全部被送入到编码器之后，所对应的 $h_{m}$ 可以认为包含了源语言序列的所有信息。

<img src="file:///D:/photos/81501dea-ffbc-4eb5-850b-849ab9357918.png" title="" alt="" style="zoom:67%;">

右侧是 **RNN 解码器部分**，它接收编码器输出的编码源语言句子信息的向量 $h_{m}$ 作为初始隐状态 $s_{0}$ 。由于 RNN 的循环过程在每个时间步都要求一个输入单词，为了启动解码过程，一般会使用一个保留的**特殊符号**`[Start]`作为翻译开始的标记送入到 RNN 解码器当中并解码出**目标语言序列**的第一个单词 $z_{1}$ 。接下来，$z_{1}$ 会作为下一个时刻的输入被送入到循环神经网络当中，并按照不断迭代产生后续的预测。由于目标语言序列的长度无法被提前预知，因此使用另一个**保留符号**`[Stop]`作为预测结束的标志。当某一个时刻 $t$ 预测出的目标语言单词为 $z_{t}$ =`[Stop]` 时，解码过程动态地停止。

在上述过程当中，主要涉及到两步运算，

第一步是 RNN 接收前一时刻隐状态 $s_{t-1}$ 并依据当前时刻输入 $z_{t-1}$（目标语言单词 $z_{t-1}$ 对应的语义嵌入）对隐状态进行维护并生成 $s_{t}$ 的运算过程，

第二步是依据当前时刻隐状态生成目标语言单词的过程：

![](file:///D:/photos/output.png)

其中 U,W,V 是可学习的参数。U,W 负责维护循环状态，而 V 负责将当前时刻状态转换到词表大小的概率分布

$P \in R^{vocab-size} $，从中可以采样得到目标语言单词 $z_{t}$。



仅仅使用一个定长的向量 $h_{m}$ 编码整个源语言序列，这对于较短的源语言文本没有什么问题，但随着文本序列长度的逐渐加长，单一的一个向量 $h_{m}$可能不足以承载源语言序列当中的所有信息。

<img src="file:///D:/photos/output%20(1).png" title="" alt="" style="zoom:67%;">

因此，我们需要引入注意力机制。



**引入注意力机制**的循环机器翻译架构与**基于简单循环网络**的机器翻译模型大体结构相似，均采用循环神经网络作为编码器与解码器的实现。关键的不同点在于**注意力机制的引入使得不再需要把原始文本中的所有必要信息压缩到一个向量当中**。引入注意力机制的循环神经网络机器翻译架构如图所示:

<img src="file:///D:/photos/output%20(2).png" title="" alt="" style="zoom:67%;">

传统的 Seq2Seq 模型在解码阶段仅依赖于编码器产生的**最后一个**隐藏状态，这在**处理长序列时效果不佳**。注意力机制允许解码器在生成每个输出词时，关注编码器产生的所有**中间状态**，从而更好地利用源序列的信息。具体来说，给定源语言序列经过编码器输出的向量序列 $h_{1},h_{2},h_{3},...,h_{m}$，**注意力机制旨在依据解码端翻译的需要，自适应地从这个向量序列中查找对应的信息**。



*我们的 baseline 代码中实现了一个经典的序列到序列(Seq2Seq)模型，中间层使用的GRU网络，并且网络中加入了注意力机制(Attention Mechanism)，请你参考上述基于注意力机制的循环神经网络机器翻译，以及GRU的相关知识，画出基于注意力机制的 GRU 神经网络机器翻译！*

* GRU 知识讲解：[9.1. 门控循环单元（GRU） — 动手学深度学习 2.0.0 documentation (d2l.ai)](https://zh.d2l.ai/chapter_recurrent-modern/gru.html)
  
  
  
  

# 翻译质量评价

这个过程也被称作**机器翻译译文质量评价**，简称为**译文质量评价**（Quality Evaluation of Translation）。译文质量评价推动着机器翻译的发展。比如，本世纪初研究人员提出了译文质量自动评价方法 **BLEU（Bilingual Evaluation Understudy）**，该方法使得机器翻译系统的评价变得自动、快速、便捷，而且评价过程可以重复。正是由于 BLEU 等自动评价方法的提出，机器翻译研究人员可以在更短的时间内得到译文质量的评价结果，加速系统研发的进程。



传统观点把翻译分为**信、达、雅**三个层次，

**信**：**忠诚度**

**达**：**流畅度**

**雅**：**不常用**



机器翻译译文评价方法的逻辑关系图：

<img src="file:///D:/photos/output%20(3).png" title="" alt="" style="zoom:67%;">

* **人工评价**：当需要对系统进行准确的评估时采用。*比如，对于机器翻译的一些互联网应用，在系统上线前都会采用人工评价对机器翻译系统性能进行测试*。当然，这种方法的时间和人力**成本最高**。

* **有参考答案的自动评价**：由于机器翻译系统研发过程中需要频繁地对系统性能进行评价，这时可以让人标注一些正确的译文，之后把这些译文作为参考答案与机器翻译系统输出的结果进行比对。这种自动评价的结果获取**成本低**，可以多次**重复**，而且可以用于对系统结果的**快速反馈**，指导系统优化的方向。

* **无参考答案的自动评价**：在很多应用场景中，在系统输出译文时，使用者希望提前知道译文的质量，即使这时并没有可比对的参考答案。这样，系统使用者可以根据这个对质量的“估计”结果有选择地使用机器翻译译文。严格意义上说，这并不是一个传统的译文质量评价方法，而是一种对译文**置信度**和**可能性**的估计。
  
  

# 遇到的问题及解决

1. 每次关闭魔搭平台的实例后只会保存`.ijupy`格式的文件。
   ——将其他文件存在本地文件夹，每次打开实例的时候再上传一次。

2. 在终端解压压缩包的时候经常显示找不到文件。
   ——终端当前位置不在目标文件夹下，需要先移到目标文件夹。


